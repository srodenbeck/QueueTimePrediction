# Methodology
## Data collection and preprocessing
We gathered data from running the sacct command from Slurm on the Anvil supercomputing cluster. Data was taken from September 2021 through May 2024, and consisted of memory requested, cpus requested, QOS, priority, planned time, job submission, start, end, and eligible time, as well as other miscellaneous information about the job and user. We selected these features over others upon researching We then used this information to create additional features regarding the resources requested by other running jobs and jobs in the queue at the time of eligibility. Eligibility was chosen as the the primary variable used to determine overlap as some jobs ability to run was contingent on another job finishing, at when they became eligible as opposed to when the user submitted the job. We applied a Box-Cox transformation to the following features to help deal with the extreme skewness in the data: [INSERT FEATURES HERE]. This data was then used in modeling to predict the planned time of jobs, which is the delay between eligibility and starting. We conducted our data preprocessing and collection using bash scripting and python scripting, as well as storing the data in a Postgres database. 
## Data Comparison
In addition to developing an artificial intelligence model to predict wait time on the Anvil supercomputer, we also investigated and compared trends in data from the past three years with data used in Karnak (ADD LINK) from (INSERT YEAR HERE, MOST LIKELY GOES TO 2017). WRITE MORE
## Model Development
